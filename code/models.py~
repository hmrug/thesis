#!/usr/bin/env python
# --- Econometics models --- 
# --- UZH MA Thesis : Scarcity channel of QE in the US --- 
# --- Autor: Hubert Mrugala (hubertmrugala.com) ---

# --- Packages --- 
import os
from datetime import datetime as dtt
from datetime import timedelta as tdelta
import numpy as np
import pandas as pd
from pandas.core.arrays.datetimes import sequence_to_datetimes
import statsmodels.api as sm
from statsmodels.formula.api import ols
import pandas_datareader.data as pdr
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import matplotlib.ticker as mtick
import seaborn as sns

# --- Options ---
pd.set_option('display.precision',4)
plt.rcParams.update({
    "figure.dpi": 100,
    "figure.figsize": [16,9],
    "font.size": 16,
    "axes.titlesize": 24,
    "axes.titleweight": "bold",
    "text.usetex": True,
    "font.family": "sans-serif",
    "font.sans-serif": ["Helvetica"]})
sns.set_style('whitegrid')
#pd.set_option("max_rows",40)

# Path to the project directory
cwd = os.getenv("THESIS_PATH")
os.chdir(cwd)
fig_path = cwd+"resources/figures/"

# --- Functions --- 
def hist_vol(series):
    vols = [series[:i].std() for i in range(len(repo))]
    return pd.Series(vols,name="Volatility",index=series.index)

def log_vol(series):
    vols = (series/series.shift()).apply(np.log)
    finite_vols = vols[np.isfinite(vols)]
    return finite_vols

# --- Data --- 
df = pd.read_csv("data/fetched_data.csv",
                 index_col="Date")
df.index = pd.to_datetime(df.index)

start_date = dtt(2008,1,2)
end_date = dtt(2021,12,31)

# Fed dates dummies
qe_dates = [
    dtt(2008,11,25), # QE1 Announced
    dtt(2008,3,16), # QE1 Expanded
    dtt(2010,8,10), # QE1 Rollover
    dtt(2010,11,3), # QE2 Announced
    dtt(2011,9,21), # Operation Twist Announced
    dtt(2012,6,20), # Operation Twist Extended
    dtt(2012,9,13), # QE3 Announced & Initiated
    dtt(2012,12,12), # QE3 Expanded
    dtt(2019,3,8), # Powell: BS endpoint will be highert than before the recession
    dtt(2019,3,20), # Fed announces intent to slow its balance sheet wind-down and then to end it
    dtt(2019,7,31), # FOMC announces end to balance sheet winddown two months earlier than previously indicated
    dtt(2019,9,20), # Continuation of Repo facility
    dtt(2019,10,11), # FOMC reaffirms Fedâ€™s intention to conduct policy that provides for an ample supply of reserves that does not require active management
    dtt(2020,3,15), # QE4
]

qt_dates = [
    dtt(2010,3,31), # QE1 Terminated
    dtt(2012,12,31), # Operation Twist Terminated
    dtt(2013,6,19), # QE3 Tapering Discussed
    dtt(2013,12,18), # QE3 Tapering Begins
    dtt(2014,9,16), # Fed issues normalization plan
    dtt(2014,10,29), # QE3 Terminated
    dtt(2017,6,14), # Fed signals BS normalization (QT)
    dtt(2017,6,14), # Fed details normalization plan
    dtt(2017,9,20), # Fed announces QT to take place in October
    dtt(2017,11,1), # QT has already begun
    dtt(2018,12,19), # Powell says BS runoff will be on autopilot
    dtt(2020,6,11) # Fed tightenes opeartions in the repo market
]

dates = pd.date_range(start_date,end_date,freq="D")

rate_changes = df["DFEDTAR"].diff()[df["DFEDTAR"].diff() != 0]

rate_up = rate_changes[rate_changes>0].index
rate_up_dates = dates.isin(rate_up)
rate_up_df = pd.Series(data=rate_up_dates,
                       index=dates)\
                    .resample("W-WED").sum()

rate_down = rate_changes[rate_changes<0].index
rate_down_dates = dates.isin(rate_down)
rate_down_df = pd.Series(data=rate_down_dates,
                       index=dates)\
                    .resample("W-WED").sum()

fed_easening = dates.isin(qe_dates)
fed_easening_df = pd.Series(data=fed_easening,
                            index=dates)\
                    .resample("W-WED").sum()

fed_tightening = dates.isin(qt_dates)
fed_tightening_df = pd.Series(data=fed_tightening,
                            index=dates)\
                    .resample("W-WED").sum()

# Taking first differences of the whole data set
ddf = df.diff()

# Add more dummies
df['D_RRP'] = df.eval('RRPONTSYD>200')
ddf["D_RRP"] = df["D_RRP"]

df["REPO_VOL"] = log_vol(df["GCF_TREASURY"])
ddf["REPO_VOL"] = df["REPO_VOL"] 

df["D_REPO_VOL"] = (df["REPO_VOL"].apply(np.abs) > 0.35) # 80% quantile
ddf["D_REPO_VOL"] = df["D_REPO_VOL"] 

df["D_PD_FAILS_ALL"] = (df["PD_FAILS_ALL"].apply(np.abs)>180000) # ?% quantile
ddf["D_PD_FAILS_ALL"] = df["D_PD_FAILS_ALL"] 

df["RATE_UP"] =  rate_up_df.astype("bool")
ddf["RATE_UP"] =  df["RATE_UP"]

df["RATE_DOWN"] =  rate_down_df
ddf["RATE_DOWN"] =  df["RATE_DOWN"]

df["FED_EASENING"] =  fed_easening_df.astype("bool")
ddf["FED_EASENING"] =  df["FED_EASENING"]

df["FED_TIGHTENING"] =  fed_tightening_df.astype("bool")
ddf["FED_TIGHTENING"] =  df["FED_TIGHTENING"]

# VOL, LIQ_T1M, LIQ_T10Y, DUMMIES


# --- OLS specifications --- 

# 1: Base
spec1 = ols("GCF_TREASURY ~\
                SOMA_TOTAL +\
                debt_held_public_amt +\
                RRPONTSYD +\
                T10Y3M +\
                C(RATE_DOWN) +\
                C(RATE_UP) +\
                C(FED_EASENING) +\
                C(FED_TIGHTENING)",
                # LIQ +\
            data=ddf,missing='drop',hasconst=True).fit()
res1 = spec1.summary()
res1

# 2: Base with RRP dummy
spec2 = ols("GCF_TREASURY ~\
                SOMA_TOTAL +\
                debt_held_public_amt +\
                C(D_RRP) +\
                T10Y3M +\
                C(RATE_UP) +\
                C(RATE_DOWN) +\
                C(FED_EASENING) +\
                C(FED_TIGHTENING) +\
                USD_ON_LIBOR",
                # LIQ +\
            data=ddf,missing='drop',hasconst=True).fit()
res2 = spec2.summary()
res2

# 3: Bills only
spec3 = ols("GCF_TREASURY ~\
                SOMA_BILLS +\
                debt_held_public_amt +\
                USD_ON_LIBOR +\
                T10Y3M +\
                C(DUMMY_RRP)",
                # LIQ +
                # DUMMIES
                # C(RATE_UP) +
                # C(RATE_DOWN) +
                # C(QE_DATE) +
                # C(QT_DATE)
            data=ddf,missing='drop',hasconst=True).fit()
res3 = spec3.summary()
res3

# 4: Collateral Spread Specfication
spec4 = ols("COL_SPREAD ~\
                SOMA_TOTAL +\
                debt_held_public_amt +\
                USD_ON_LIBOR +\
                T10Y3M +\
                C(D_RRP)",
                # LIQ +
                # DUMMIES
                # C(RATE_UP) +
                # C(RATE_DOWN) +
                # C(QE_DATE) +
                # C(QT_DATE)
            data=ddf,missing='drop',hasconst=True).fit()
res4 = spec4.summary()
res4

# 5: Extended model: added proxy for collateral-reuse and depressed secured market
spec52 = ols("COL_SPREAD ~\
                SOMA_TOTAL +\
                debt_held_public_amt +\
                T10Y3M +\
                USD_ON_LIBOR +\
                C(D_PD_FAILS_ALL)",
                # LIQ +
                # DUMMIES
                # C(RATE_UP) +
                # C(RATE_DOWN) +
                # C(QE_DATE) +
                # C(QT_DATE)
            data=ddf,missing='drop',hasconst=True).fit()
res52 = spec52.summary()
res52

spec52 = ols("GCF_TREASURY ~\
                SOMA_TOTAL +\
                debt_held_public_amt +\
                T10Y3M +\
                USD_ON_LIBOR +\
                C(D_REPO_VOL)",
                # LIQ +
                # DUMMIES
                # C(RATE_UP) +
                # C(RATE_DOWN) +
                # C(QE_DATE) +
                # C(QT_DATE)
            data=ddf,missing='drop',hasconst=True).fit()
res52 = spec52.summary()
res52


# Minor specific specs
# YC intepretation
specx = ols("GCF_TREASURY ~\
                USD_ON_LIBOR +\
                T10Y3M +\
                RRPONTSYD",
                # VOL
                # LIQ +
                # DUMMIES
                # C(RATE_UP) +
                # C(RATE_DOWN) +
                # C(QE_DATE) +
                # C(QT_DATE)
            data=ddf,missing='drop',hasconst=True).fit()
resx = specx.summary()
resx

# Extended model: collateral spread
specx = ols("COL_SPREAD ~\
                SOMA_TOTAL +\
                debt_held_public_amt +\
                T10Y3M +\
                C(DUMMY_RRP) +\
                PD_FAILS_ALL",
                # VOL
                # LIQ +
                # T10Y3M +\
                # DUMMIES
                # C(RATE_UP) +
                # C(RATE_DOWN) +
                # C(QE_DATE) +
                # C(QT_DATE)
            data=ddf,missing='drop',hasconst=True).fit()
resx= specx.summary()
resx

# --- Figures --- 

## Figure 1: Collateral Spread
f_1, ax = plt.subplots(1,1)
ax.xaxis.set_major_locator(mdates.MonthLocator(interval=3))
ax.xaxis.set_major_formatter(mdates.DateFormatter("%b \'%y"))
ax.tick_params(axis='x', rotation=45)
ax.plot(coll_spread.loc[start:end]*100,c='k',lw=3)
ax.set_ylabel("bps")
ax.axhline(0,c='C3')
ax.set_title("Collateral Spread")
ax.set_xlim(start)
sns.despine()
plt.tight_layout()
# f_1.savefig(fig_path+"collateral_spread.pdf")


#df.plot(subplots=True,layout=(6,6))



